# Working with Apache Kafka

The objective of this tutorial is to get started using Apache Kafka.

## Install Kafka

You can download th latest version (v-2.2.0 as of the time of writing this tutorial) of Apache Kafka from
there [download page](https://www.apache.org/dyn/closer.cgi?path=/kafka/2.2.0/kafka_2.12-2.2.0.tgz).

```
tar -xzvf kafka_2.12-2.2.0.tgz
mv kafka_2.12-2.2.0 kafka
```

## Run Zookeeper

Kafka uses Zookeeper for various tasks including:

* Electing a controller and ensuring there is only one and elect a new one if it
  crashes.
* Maintaining the Kafka cluster membership to track brokers joins and leaves:
  which brokers are part of the cluster.
* Topic configuration management to track existing topics, topics partitions,
  topics replicas, etc.
* Quota configuration: defining the maximum bandwidth and CPU utilization a
  Kafka client can use.
* ACL configuration: defining the access rights of Kafka clients to read/write
  from/to topics.

For the purpose of this tutorial, we will use a single node (non production)
Zookeeper cluster. Kafka provides a convenient Zookeeper startup script
`./bin/zookeeper-server-start.sh` with its minimalistic configuration file
`./config/zookeeper.properties`:


```
./bin/zookeeper-server-start.sh config/zookeeper.properties
```

You should get the following output log. Zookeeper is now up and running
listening on port number `2181`.

```
...
[2018-03-30 12:38:33,664] INFO Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni:/lib:/usr/lib (org.apache.zookeeper.server.ZooKeeperServer)
[2018-03-30 12:38:33,666] INFO Server environment:java.io.tmpdir=/tmp (org.apache.zookeeper.server.ZooKeeperServer)
[2018-03-30 12:38:33,666] INFO Server environment:java.compiler=<NA> (org.apache.zookeeper.server.ZooKeeperServer)
[2018-03-30 12:38:33,666] INFO Server environment:os.name=Linux (org.apache.zookeeper.server.ZooKeeperServer)
[2018-03-30 12:38:33,667] INFO Server environment:os.arch=amd64 (org.apache.zookeeper.server.ZooKeeperServer)
[2018-03-30 12:38:33,667] INFO Server environment:os.version=4.13.0-36-generic (org.apache.zookeeper.server.ZooKeeperServer)
[2018-03-30 12:38:33,667] INFO Server environment:user.name=bachwehbi (org.apache.zookeeper.server.ZooKeeperServer)
[2018-03-30 12:38:33,667] INFO Server environment:user.home=/home/bachwehbi (org.apache.zookeeper.server.ZooKeeperServer)
[2018-03-30 12:38:33,667] INFO Server environment:user.dir=/home/bachwehbi/dev/kafka (org.apache.zookeeper.server.ZooKeeperServer)
[2018-03-30 12:38:33,681] INFO tickTime set to 3000 (org.apache.zookeeper.server.ZooKeeperServer)
[2018-03-30 12:38:33,690] INFO minSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2018-03-30 12:38:33,690] INFO maxSessionTimeout set to -1 (org.apache.zookeeper.server.ZooKeeperServer)
[2018-03-30 12:38:33,717] INFO binding to port 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.NIOServerCnxnFactory)

```

## Running Kafka

The Kafka package comes with a ready to use configuration file `config/server.properties`.
Let's review the main points in this file:

### Kafka Configuration Options

#### Broker id

Every broker in a Kafka cluster must have a unique identifier.

```
############################# Server Basics #############################

# The id of the broker. This must be set to a unique integer for each broker.
broker.id=0

```

#### Broker Socket settings

The broker socket settings include the hostname and port number the broker
listens to and the hostname and post it will advertise to producers and consumers.
By default, Kafka listens on local hostname and port number 9092.

```
############################# Socket Server Settings #############################

# The address the socket server listens on. It will get the value returned from
# java.net.InetAddress.getCanonicalHostName() if not configured.
#   FORMAT:
#     listeners = listener_name://host_name:port
#   EXAMPLE:
#     listeners = PLAINTEXT://your.host.name:9092
#listeners=PLAINTEXT://:9092

# Hostname and port the broker will advertise to producers and consumers. If not set,
# it uses the value for "listeners" if configured.  Otherwise, it will use the value
# returned from java.net.InetAddress.getCanonicalHostName().
#advertised.listeners=PLAINTEXT://your.host.name:9092

```

#### Zookeeper settings

Kafka broker needs to connect to Zookeeper. The Zookeeper settings provide the
connection string (one or multiple hostname:port) of Zookeeper cluster.
By default, Kafka assumes a local Zookeeper is running on port number 2181.

```
############################# Zookeeper #############################

# Zookeeper connection string (see zookeeper docs for details).
# This is a comma separated host:port pairs, each corresponding to a zk
# server. e.g. "127.0.0.1:3000,127.0.0.1:3001,127.0.0.1:3002".
# You can also append an optional chroot string to the urls to specify the
# root directory for all kafka znodes.
zookeeper.connect=localhost:2181

# Timeout in ms for connecting to zookeeper
zookeeper.connection.timeout.ms=6000
```

### Run Kafka

You can now start the Kafka cluster with:

```
./bin/kafka-server-start.sh config/server.properties
```

You should get the following output log. A Kafka instance is up and running!

```
...
[2019-03-30 13:07:19,734] INFO Registered broker 0 at path /brokers/ids/0 with addresses: EndPoint(bachwehbi-VirtualBox,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.utils.ZkUtils)
[2019-03-30 13:07:19,736] WARN No meta.properties file under dir /tmp/kafka-logs/meta.properties (kafka.server.BrokerMetadataCheckpoint)
[2019-03-30 13:07:19,808] INFO Kafka version : 2.2.0 (org.apache.kafka.common.utils.AppInfoParser)
[2019-03-30 13:07:19,822] INFO Kafka commitId : c0518aa65f25317e (org.apache.kafka.common.utils.AppInfoParser)
[2019-03-30 13:07:19,830] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
```

## Working with topics

### Create a topic

Now that the Kafka broker is running, it's time to work with topics.
Kafka provides a utilities script to work with topics `kafka-topics.sh`.
To create a new topic named `test1` run the following:

```
./bin/kafka-topics.sh --create --zookeeper localhost:2181 \
  --replication-factor 1 --partitions 1 --topic test1
```

This creates a new topic named `test1` with 1 partition and without replication.
With our single node Kafka cluster, it is possible to partition topics but it
won't be possible to replicate data. The latter requires a multi-node cluster.

For a partitioned topic run the following:
```
./bin/kafka-topics.sh --create --zookeeper localhost:2181 \
  --replication-factor 1 --partitions 3 --topic my-partitioned-topic
```

Try now to set `replication-factor` to 3. We will receive an error indicating
that the replication factor is larger than available brokers.

```
./bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 3 --partitions 13 --topic test3

Error while executing topic command : Replication factor: 3 larger than available brokers: 1.
[2018-03-30 15:37:24,227] ERROR org.apache.kafka.common.errors.InvalidReplicationFactorException: Replication factor: 3 larger than available brokers: 1.
 (kafka.admin.TopicCommand$)

```

### Listing existing topics

Existing topics can be listed by running the following command:
```
./bin/kafka-topics.sh --list --zookeeper localhost:2181
test1
test2
```

### Describing a topic

We can alo describe a particular topic using:
```
./bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic test1
    Topic:test1	PartitionCount:1	ReplicationFactor:1	Configs:
    Topic: test1	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
```

### Auto-creating topics

It is possible to configure Kafka to auto-create topics when a non existent
topic is published to. In production deployments, it is however not recommended
to enable this feature as it might lead to the undesired creation of a large
amount of topics.

## Writing to Kafka

Kafka provides a command line producer utility to send messages out to a Kafka
topic. The utility called `kafka-console-producer.sh` takes input from a file
or from the standard input. You can use it as follows:

```
./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test1
>message 1
>message 2
>message 3
```

Write a text message and press enter to publish it to the topic. To send multiple
 messages, you can repeat this process as many times as you wish.

## Consuming messages

Kafka also has a command line consumer utility that will subscribe to a topic
dump out received messages to the standard output. Start the consumer as follows:

```
./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test1 --from-beginning
message 1
message 2
message 3
```

When running the consumer, you will receive all the messages published to that
topic. Re-run the same command and see how you will get the same messages over
and over again. This is because of the `--from-beginning` option that instructs
the consumer to request all data on the commit log of the topic.

Now go back to the producer console and publish additional messages and see how
the consumer receives them in real time.

You can also specify the offset id from which to consume from. When specifying
an offset, it is required to specify the partition as well as Kafka maintains an
ordered offset per partition.

```
./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 \
    --topic test1 --partition 0 --offset 2
message 3
message 4
message 5
```

You see that messages are delivered in the insertion order. This is because the
topic `test1` is single partitioned. Let's now try to work with partitioned
topic `my-partitioned-topic` we already created.

Now start a couple of additional consumers in separate terminals and go back to
your producer to send few messages. See how messages are received by all consumers?
This is because each consumer is in a different `consumer group`.
We will work with consumer groups later in this tutorial.

## Working with partitioned topics

Publishing to a partitioned topic is exactly as publishing to a single partition topic.

```
./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic my-partitioned-topic
>message 1
>message 2
>message 3
>message 4
>message 5
>message 6
```

Describing the topic shows its 3 non replicated partitions:

```
./bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-partitioned-topic
Topic:my-partitioned-topic	PartitionCount:3	ReplicationFactor:1	Configs:
	Topic: my-partitioned-topic	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
	Topic: my-partitioned-topic	Partition: 1	Leader: 0	Replicas: 0	Isr: 0
	Topic: my-partitioned-topic	Partition: 2	Leader: 0	Replicas: 0	Isr: 0
```

Now start a consumer console utility:
```
./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic my-partitioned-topic --from-beginning
message 3
message 6
message 1
message 4
message 2
message 5
```

Messages are not delivered in the publishing order here. This is the normal
behaviour of Kafka as it guarantees order within every partition. To see this,
let's read messages from the topic's 3 partitions:

```
./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 \
     --topic my-partitioned-topic --partition 0 --offset 0
message 2
message 5

./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 \
    --topic my-partitioned-topic --partition 1 --offset 0
message 1
message 4

./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 \
    --topic my-partitioned-topic --partition 2 --offset 0
message 3
message 6
```

See how messages were delivered in order from every partition. The key point
here is to remember that Kafka orders messages per partition and not per topic.

## Working with consumer groups

### Consumer group utility

In what we have seen so far, consumers were started without explicitly indicating
there group identifier. In this case, the consumer self assigns a (randomly)
chosen group id where it is the only consumer.

Kafka provides a utility to work with consumer groups `kafka-consumer-groups.sh`.
Let's list the groups known by our cluster:

```
./bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list
Note: This will not show information about old Zookeeper-based consumers.

console-consumer-16911
console-consumer-83013
console-consumer-43569
console-consumer-77790
console-consumer-20314
...
```

We can see the different consumer groups that were automatically created by our
previous consumers. We can also check the details of a particular group to see
consumer positions per partition:

```
./bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group console-consumer-20314

Note: This will not show information about old Zookeeper-based consumers.


TOPIC                          PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG        CONSUMER-ID                                       HOST                           CLIENT-ID
my-partitioned-topic           0          2               2               0          consumer-1-2fb58ed7-81b6-4c8c-9a28-6638f44c7070   /127.0.0.1                     consumer-1
my-partitioned-topic           1          2               2               0          consumer-1-2fb58ed7-81b6-4c8c-9a28-6638f44c7070   /127.0.0.1                     consumer-1
my-partitioned-topic           2          2               2               0          consumer-1-2fb58ed7-81b6-4c8c-9a28-6638f44c7070   /127.0.0.1                     consumer-1
```

We can also use the consumer group utility to check members in a particular
consumer group:

```
./bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group console-consumer-20314 --members

CONSUMER-ID                                    HOST            CLIENT-ID       #PARTITIONS
consumer-1-2fb58ed7-81b6-4c8c-9a28-6638f44c7070 /127.0.0.1     consumer-1      3
```

### Consuming messages in a consumer group

To start a consumer in a consumer group, we need just to add an option
`--consumer-property group.id=GROUP_NAME` before running the consumer.

Open 3 terminal windows and run the following command:

```
./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic my-partitioned-topic --from-beginning --consumer-property group.id=group1
```

Go back to the producer terminal and publish few messages. See how these messages
are delivered evenly between the different consumers. Kafka requires every topic
partition messages to be delivered to a single consumer in a consumer group.

Describe the consumer group to see how this is reflected:

```
./bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group group1

Note: This will not show information about old Zookeeper-based consumers.


TOPIC                          PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG        CONSUMER-ID                                       HOST                           CLIENT-ID
my-partitioned-topic           0          4               4               0          consumer-1-0af5a5ca-72e5-4328-b68b-e0949d07c2b9   /127.0.0.1                     consumer-1
my-partitioned-topic           2          4               4               0          consumer-1-d60f1be2-b03b-4e1d-91ef-418588e530f2   /127.0.0.1                     consumer-1
my-partitioned-topic           1          4               4               0          consumer-1-2ff1f615-28fd-49cf-9ade-e8393c687573   /127.0.0.1                     consumer-1

```

As our topic has 3 partitions, what would happen if we start a 4th consumer in the group?

Nothing, see :)

```
./bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --group group1

Note: This will not show information about old Zookeeper-based consumers.


TOPIC                          PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG        CONSUMER-ID                                       HOST                           CLIENT-ID
my-partitioned-topic           0          4               4               0          consumer-1-0af5a5ca-72e5-4328-b68b-e0949d07c2b9   /127.0.0.1                     consumer-1
my-partitioned-topic           2          4               4               0          consumer-1-d60f1be2-b03b-4e1d-91ef-418588e530f2   /127.0.0.1                     consumer-1
my-partitioned-topic           1          4               4               0          consumer-1-2ff1f615-28fd-49cf-9ade-e8393c687573   /127.0.0.1                     consumer-1
-                              -          -               -               -          consumer-1-d60f1be2-b03b-4e1d-91ef-418588e530f2   /127.0.0.1                     consumer-1

```

the 4th consumer will not receive any messages as there are more consumers in the
group than partitions in the topic. However, this consumer will be ready to take
over in case of consumer failure.

In the next section, we will try to understand the failover strategies of Kafka.

## Kafka Fault Tolerance

### Running a multi-broker cluster

So far we have worked with a single broker Kafka cluster. Although this is fine
for dev and debug purposes, it is important to have a proper multi node cluster
for production. A Kafka cluster is composed of multiple brokers running on
different physical or virtual machines and potentially across multiple data
centres. For the purpose our this tutorial, we will run a Kafka cluster composed
of 3 brokers running on the same machine. Every broker will be listening to a
different port number.

Every broker needs its own configuration file, so let's start by duplicating the
configuration file of our existing broker:

```
cp config/server.properties config/server1.properties
cp config/server.properties config/server2.properties
```

Open the newly created configuration files in your favourite text editor, locate
the lines corresponding to: `broker.id`, `port`, and, `log.dirs` properties and
change them as follows:

```
config/server1.properties:
    ...
    broker.id=1
    listeners=PLAINTEXT://:9093
    log.dir=/tmp/kafka-logs1
    ...

config/server-2.properties:
    ...
    broker.id=2
    listeners=PLAINTEXT://:9094
    log.dir=/tmp/kafka-logs2
```

Now open two terminal windows and start two additional Kafka brokers with these
configuration files:

*Start second broker in a new terminal window*
```
./bin/kafka-server-start.sh config/server1.properties
```

*Start the third broker in a another terminal window*
```
./bin/kafka-server-start.sh config/server2.properties
```

Great! Now you have a Kafka cluster with 3 brokers connected to a single node
Zookeeper cluster.

In the next two sections, we will see Kafka failover in action.

### Create a replicated topic

In the previous sections of this tutorial, we created a single partitioned and a
multi partitions topics. There were no replication as we had only one broker.
Let's create now a replicated topic. With replication, Kafka achieves data
durability and tolerance to broker failures.

```
./bin/kafka-topics.sh --create --zookeeper localhost:2181 \
  --replication-factor 3 --partitions 3 --topic my-replicated-topic
```

This creates a topic named `my-replicated-topic` with three partitions replicated
over three brokers each. As our cluster has 3 brokers, this would work just fine.

Let's `describe` the topic and see what Kafka tells us about it:
```
./bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic
Topic:my-replicated-topic	PartitionCount:3	ReplicationFactor:3	Configs:
	Topic: my-replicated-topic	Partition: 0	Leader: 1	Replicas: 1,0,2	Isr: 1,0,2
	Topic: my-replicated-topic	Partition: 1	Leader: 2	Replicas: 2,1,0	Isr: 2,1,0
	Topic: my-replicated-topic	Partition: 2	Leader: 0	Replicas: 0,2,1	Isr: 0,2,1
```

Kafka has distributed the responsibilities evenly between the different brokers.
Every topic partition has its own leader (broker) and a list of replicas and an
indication if they are in-sync with the leader (the `Isr` list).

### Consumer failure

We will now start 3 consumers in the same consumer group. Open 3 terminal windows
and run the following command:

```
./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092,localhost:9093 --topic my-replicated-topic --from-beginning --consumer-property group.id=rep-group
```

Once the three consumers are running, we will use the console producer utility
to send some messages to the topic:

```
./bin/kafka-console-producer.sh --broker-list localhost:9092,localhost:9093 --topic my-replicated-topic
>message 1
>message 2
>message 3
>message 4
>message 5
>message 6
```
See how the consumers get a share of the messages. Every message is received by
one of the consumers in the group.

```
./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092,localhost:9093 --topic my-replicated-topic --from-beginning --consumer-property group.id=rep-group
message 1
message 4

./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092,localhost:9093 --topic my-replicated-topic --from-beginning --consumer-property group.id=rep-group
message 2
message 5

./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092,localhost:9093 --topic my-replicated-topic --from-beginning --consumer-property group.id=rep-group
message 3
message 6
```

The good thing with consumer groups is that not only load is distributed among
the consumers, it also gets reconfigured when a consumer fails or leaves the group.

To show this, stop one of the consumers and send 6 additional messages
(*message 7* - *message 12*) from the producer.

```
./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092,localhost:9093 --topic my-replicated-topic --from-beginning --consumer-property group.id=rep-group
message 1
message 4
message 7
message 9
message 10
message 12

./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092,localhost:9093 --topic my-replicated-topic --from-beginning --consumer-property group.id=rep-group
message 2
message 5
message 8
message 11

./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092,localhost:9093 --topic my-replicated-topic --from-beginning --consumer-property group.id=rep-group
message 3
message 6
^CProcessed a total of 2 messages
```

When one of the consumers was stopped, Kafka automatically redistributed the
topic partitions among the remaining consumers. As the topic has 3 partitions
and only 2 consumers were left in the group, one of the consumers was attributed
2 partitions while the other was attributed the third one.

This is how Kafka consumer group fault tolerance works. The Kafka cluster will
reconfigure the partition distribution among the consumers in the group with
every consumer join or leave.

### Broker Failure

Let's now simulate a broker failure by stopping on of the brokers in the cluster.

Open one of the broker terminals and hit `CTRL-C`, this will stop the broker.

Once the broker has stopped, describe the topic:

```
./bin/kafka-topics.sh --describe --zookeeper localhost:2181 --topic my-replicated-topic

Topic:my-replicated-topic	PartitionCount:3	ReplicationFactor:3	Configs:
	Topic: my-replicated-topic	Partition: 0	Leader: 0	Replicas: 1,0,2	Isr: 0,2
	Topic: my-replicated-topic	Partition: 1	Leader: 2	Replicas: 2,1,0	Isr: 0,2
	Topic: my-replicated-topic	Partition: 2	Leader: 0	Replicas: 0,2,1	Isr: 0,2
```

See how the leaders for the topic partitions have been reconfigured to account
for the failed broker. Similarly for the in-sync list.

Now to show that the cluster continues to work normally in the presence of broker
failure, go back to the producer terminal and send a bunch of messages.

See how all published messages have been delivered to the active consumers?

Voilà :)

## Publish Key:Value messages

So far we have been working with messages without keys. It is possible to send
`Key:Value` messages to a topic. This allows to group together messages belonging
to the same key. On a partitioned topic, all messages with the same key will be
sent by the producer to the same partition.

Using the Kafka console producer, you can send keyed messages as follows:

```
./bin/kafka-console-producer.sh \
  --broker-list localhost:9092 \
  --property "parse.key=true" \
  --property "key.separator=:"
  --topic topicwithkey

> key1:val1
> key2:val2
> key3:val3
```
